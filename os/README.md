# os에 대해서


- [프로세스와 스레드](#프로세스와-스레드)
- [프로세스의 상태 PCB TCB 커널스레드 유저스레드](#프로세스의-상태-PCB-TCB-커널스레드-유저스레드)
- [스케줄러](#스케줄러)
- [cpu 스케줄러](#cpu-스케줄러)
- [프로세스 동기화](#프로세스-동기화)


<br>
<br>
<hr>


## 프로세스와 스레드

**프로세스**와 **스레드**는 운영체제에서 중요한 개념으로, 컴퓨터 시스템에서 작업을 수행하는 단위입니다. 두 개념은 작업을 나누고 실행하는 방식에서 차이가 있습니다. **프로세스**는 운영체제에서 독립된 실행 단위이고, **스레드**는 프로세스 내에서 작업을 실행하는 더 작은 실행 단위입니다.

### **1. 프로세스(Process)란?**

<img width="330" alt="image" src="https://github.com/user-attachments/assets/4fc9ebc6-c0ec-4f85-a025-21effccde1c4">


**프로세스**는 운영체제에서 **실행 중인 프로그램**을 의미합니다. 각각의 프로세스는 **자체의 메모리 공간과 시스템 자원**을 할당받아 독립적으로 실행됩니다.

- **메모리**: 프로세스는 독립적인 메모리 공간을 가집니다. 코드, 데이터, 스택, 힙 등으로 분리된 메모리 영역이 할당됩니다.
- **보호된 환경**: 각 프로세스는 **독립적**이므로, 한 프로세스가 다른 프로세스의 메모리나 자원에 직접 접근할 수 없습니다. 따라서 프로세스 간 통신(IPC, Inter-Process Communication)은 운영체제를 통해 이루어집니다.
- **문맥 교환**: 여러 프로세스가 동시에 실행되는 환경에서는 운영체제가 각 프로세스 사이에서 **문맥 교환(Context Switching)**을 수행합니다. 문맥 교환은 CPU가 하나의 프로세스에서 다른 프로세스로 전환될 때의 작업입니다. 이때, 이전 프로세스의 상태를 저장하고, 새로 실행할 프로세스의 상태를 복원하는 과정에서 오버헤드가 발생할 수 있습니다.

**프로세스의 예시**:
- 사용자가 실행한 웹 브라우저나 텍스트 편집기, 백그라운드에서 실행 중인 시스템 프로세스 등이 모두 운영체제에서 각각의 독립된 프로세스로 실행됩니다.

### **2. 스레드(Thread)란?**

**스레드**는 **프로세스 내에서 실행되는 작업의 흐름**으로, 프로세스의 실행 단위를 더욱 세분화한 개념입니다. **한 프로세스는 여러 스레드**를 가질 수 있으며, 이들 스레드는 같은 메모리 공간을 공유합니다.

- **메모리 공유**: 같은 프로세스 내의 스레드들은 **코드, 데이터, 힙**을 공유합니다. 하지만 각 스레드는 **자신만의 스택과 레지스터**를 가지고 독립적으로 실행됩니다.
- **경량화**: 스레드는 같은 프로세스 내에서 **공유된 메모리 공간**을 사용하므로, 프로세스 간의 문맥 교환보다 훨씬 **빠르게** 전환할 수 있습니다.
- **병렬 처리**: 하나의 프로세스에서 여러 스레드를 생성하면, 여러 스레드가 병렬로 작업을 수행할 수 있습니다. 이는 다중 코어 CPU 환경에서 특히 유리합니다.

**스레드의 예시**:
- 웹 브라우저에서 여러 탭을 동시에 처리하거나, 게임에서 물리 연산과 렌더링 작업을 병렬로 처리하는 경우, 각각의 작업은 스레드로 나눠집니다.

### **3. 프로세스와 스레드의 차이점**

| **특징**               | **프로세스(Process)**                        | **스레드(Thread)**                         |
|------------------------|---------------------------------------------|--------------------------------------------|
| **메모리**             | 독립적인 메모리 공간을 가짐                 | 같은 프로세스 내에서 메모리(코드, 데이터, 힙)를 공유 |
| **문맥 교환**          | 문맥 교환 시 오버헤드가 큼                   | 스레드 간 문맥 교환은 빠름                 |
| **실행 단위**          | 독립적인 실행 단위                          | 프로세스 내의 경량 실행 단위               |
| **오류 영향**          | 한 프로세스가 종료되면 다른 프로세스에 영향 없음 | 한 스레드가 비정상 종료되면 같은 프로세스 내 다른 스레드에 영향 가능 |
| **통신**               | IPC(프로세스 간 통신)를 통해서만 가능         | 같은 프로세스 내에서는 직접 메모리 접근 가능 |
| **사용 사례**          | 독립된 프로그램 실행                        | 병렬 작업 처리, 다중 작업 처리             |

### **4. 프로세스와 스레드의 장단점**

#### **프로세스의 장점**:
- **안정성**: 프로세스는 서로 독립적이기 때문에, 하나의 프로세스가 오류를 일으키더라도 다른 프로세스에 영향을 주지 않습니다.
- **보안성**: 각 프로세스는 별도의 메모리 공간을 가지고 있어, 메모리 침범이 어렵습니다.

#### **프로세스의 단점**:
- **비용**: 프로세스 간 문맥 교환이 빈번하게 일어나면 성능 저하가 발생할 수 있습니다.
- **통신 비용**: 서로 다른 프로세스 간의 데이터 공유나 통신은 IPC 메커니즘을 통해 이루어져야 하므로, 성능 오버헤드가 큽니다.

#### **스레드의 장점**:
- **성능**: 스레드는 같은 프로세스 내에서 메모리를 공유하므로, 문맥 교환이 프로세스 간 교환보다 빠릅니다.
- **메모리 절약**: 같은 프로세스의 자원을 공유하기 때문에, 여러 스레드가 생성되어도 메모리 사용량이 크게 증가하지 않습니다.

#### **스레드의 단점**:
- **안정성**: 한 스레드가 오류를 일으키면 같은 프로세스 내의 다른 스레드에도 영향을 미칠 수 있습니다.
- **복잡성**: 여러 스레드가 동시에 같은 자원에 접근할 때 **동기화 문제**(Race Condition, Deadlock 등)가 발생할 수 있어, 이를 처리하기 위한 추가적인 관리가 필요합니다.

### **5. 프로세스와 스레드의 사용 예시**

- **프로세스**: 웹 브라우저, 텍스트 에디터, 음악 재생 프로그램 등 독립적인 애플리케이션은 각각 하나의 프로세스로 실행됩니다.
- **스레드**: 웹 브라우저의 각 탭, 게임의 물리 엔진과 그래픽 처리, 웹 서버의 다중 클라이언트 요청 처리 등이 각각 스레드로 처리되어 병렬 작업이 가능합니다.

### **결론**

**프로세스**는 운영체제에서 독립적으로 실행되는 프로그램으로, 각자 고유한 메모리와 시스템 자원을 가지며, 서로 간섭하지 않고 안정적으로 실행됩니다. 반면에 **스레드**는 같은 프로세스 내에서 여러 작업을 병렬로 처리할 수 있는 경량화된 실행 단위로, 메모리를 공유하며 보다 빠르게 작업을 수행할 수 있지만, 동기화 문제에 주의해야 합니다.



<br>
<br>
<br>
<hr>

## 프로세스의 상태 PCB TCB 커널스레드 유저스레드

### **1. 프로세스의 상태 (Process States)**
![image](https://github.com/user-attachments/assets/f23904c7-6662-4cac-9c03-6ef3cbc779c6)

프로세스는 실행되는 동안 여러 상태를 거칩니다. 일반적으로 프로세스는 다음과 같은 주요 상태를 가집니다:

- **New(생성)**: 프로세스가 막 생성되어 실행을 준비하는 단계입니다. 아직 메모리에 올라가거나 실행되지는 않은 상태입니다.
  
- **Ready(준비)**: 프로세스가 실행될 준비가 완료된 상태입니다. CPU에서 실행되기를 기다리고 있으며, 실행 가능한 상태입니다. 그러나 CPU 할당을 받지 못한 상태입니다.
  
- **Running(실행 중)**: 프로세스가 CPU에서 실행되고 있는 상태입니다. Ready 상태에 있던 프로세스가 CPU를 할당받아 실행되면 Running 상태로 전환됩니다.

- **Blocked(대기)**: 프로세스가 **입출력(I/O) 작업**과 같은 외부 자원을 기다리고 있는 상태입니다. CPU는 사용하지 않으며, 자원이 준비될 때까지 대기 상태에 있습니다.

- **Terminated(종료)**: 프로세스가 **완료되거나 종료된** 상태입니다. 프로세스가 정상적으로 완료되거나 오류로 인해 종료되면 이 상태로 진입합니다.

- **Suspended(중지)**: 프로세스가 **메모리에서 완전히 내려간 상태**입니다. 주로 시스템 자원이 부족할 때 사용되며, 다시 실행되려면 메모리에 다시 올라가야 합니다.

이러한 상태들은 운영체제가 프로세스를 관리하기 위한 기본적인 상태 변화를 나타내며, **문맥 교환(Context Switching)** 과정에서 프로세스의 상태가 변경됩니다.

**+) 프로세스의 Running State에서 CPU 자원을 뺐기는 3가지 상황**
- Interrupt가 발생했을 때 (timer도 포함)
- I/O request를 하기 위해 system call을 하여 waiting상태로 넘어가는 경우
- Process의 수행이 끝나서 terminated로 되는 경우
  
---

### **2. 프로세스 제어 블록 (PCB, Process Control Block)**

**PCB(Process Control Block)**는 운영체제가 프로세스를 관리하기 위해 사용하는 **데이터 구조**입니다. 프로세스에 대한 중요한 정보를 저장하고 있으며, **프로세스 상태 변화** 시 PCB를 참조하여 관리합니다. PCB는 다음과 같은 정보들을 포함합니다:

- **프로세스 상태**: 프로세스가 현재 어떤 상태에 있는지 나타냅니다(Ready, Running, Blocked 등).
- **프로세스 ID**: 운영체제가 프로세스를 식별하기 위해 부여하는 고유 ID.
- **레지스터 정보**: 프로세스가 CPU에서 실행되던 시점의 레지스터 값들을 저장합니다.
- **프로세스 우선순위**: 프로세스가 CPU를 얼마나 자주, 얼마나 빨리 할당받을지를 결정하는 우선순위 값.
- **프로그램 카운터**: 프로세스가 실행 중이던 마지막 명령어의 주소를 저장합니다.
- **메모리 관리 정보**: 프로세스에 할당된 메모리 정보(스택, 힙, 데이터 영역 등).
- **입출력 상태 정보**: 프로세스와 관련된 입출력 장치 상태 정보.

운영체제는 PCB를 기반으로 각 프로세스를 관리하며, 문맥 교환이 일어날 때 PCB에 저장된 정보가 CPU에 다시 로드됩니다.

---

### **3. 스레드 제어 블록 (TCB, Thread Control Block)**

**TCB(Thread Control Block)**는 **스레드의 정보를 관리하는 데이터 구조**입니다. 스레드 역시 프로세스와 유사하게 제어되어야 하기 때문에 운영체제는 각 스레드의 상태를 관리합니다. TCB는 다음과 같은 정보를 포함합니다:

- **스레드 ID**: 스레드를 구분하기 위한 고유 식별자.
- **스레드 상태**: 스레드의 현재 상태(Ready, Running, Blocked 등).
- **프로그램 카운터**: 스레드가 실행 중이던 명령어 주소.
- **레지스터 정보**: 스레드 실행 시 사용한 레지스터 값.
- **스레드 우선순위**: 스레드의 실행 우선순위를 나타내는 값.

TCB는 스레드가 여러 개 있는 환경에서 각 스레드의 실행 상태를 관리하고, 문맥 교환 시 각 스레드의 상태를 저장하고 복구하는 역할을 합니다.

---

### **4. 커널 스레드 (Kernel Thread)**

**커널 스레드**는 **운영체제가 직접 관리하는 스레드**로, 커널 모드에서 실행됩니다. 커널 스레드는 **운영체제 내에서 실행되는 스레드**이기 때문에 운영체제가 모든 것을 제어하며, 스레드의 생성, 스케줄링, 종료 등이 **커널에 의해 관리**됩니다.

- **장점**: 커널이 스레드를 직접 관리하므로, 여러 스레드가 동시에 CPU를 사용할 수 있으며, 멀티코어 환경에서 병렬 처리가 가능합니다.
- **단점**: 커널에서 직접 스레드를 관리하므로, **문맥 교환 비용**이 높고, 스레드 생성 및 관리에 대한 오버헤드가 큽니다.

**예시**: 대부분의 운영체제에서 사용하는 기본적인 스레드 관리 방식입니다. Windows, Linux 등에서 커널 스레드를 지원하며, 스레드의 동작을 최적화합니다.

---

### **5. 유저 스레드 (User Thread)**

**유저 스레드**는 **사용자 레벨에서 관리되는 스레드**로, 운영체제가 아닌 사용자 수준의 라이브러리에서 스레드를 관리합니다. 커널은 유저 스레드의 존재를 인식하지 못하며, 하나의 유저 스레드는 하나의 커널 스레드와 연결되지 않을 수 있습니다.

- **장점**: 문맥 교환이 **커널의 개입 없이 빠르게** 이루어지며, 스레드 생성과 관리에 드는 오버헤드가 적습니다.
- **단점**: 유저 스레드는 운영체제가 직접 관리하지 않기 때문에, **동시에 여러 스레드가 실행되지 못하는 경우**가 발생할 수 있습니다. 또한, 하나의 유저 스레드가 차단되면 전체 프로세스가 차단될 수 있습니다.

**예시**: `POSIX Threads (pthreads)`와 같은 라이브러리는 유저 스레드를 구현하는 대표적인 예입니다.

---

### **커널 스레드와 유저 스레드의 차이점**

| **특징**              | **커널 스레드(Kernel Thread)**               | **유저 스레드(User Thread)**                |
|-----------------------|----------------------------------------------|---------------------------------------------|
| **관리 주체**          | 운영체제가 직접 관리                         | 사용자 수준의 라이브러리에서 관리            |
| **문맥 교환 비용**     | 문맥 교환 비용이 높음                        | 문맥 교환 비용이 낮음                       |
| **동시성 지원**        | 멀티코어 환경에서 동시 실행 가능             | 동시 실행이 제한될 수 있음                   |
| **스레드 차단 시**     | 하나의 스레드가 차단되어도 다른 스레드는 실행 | 하나의 스레드가 차단되면 전체 프로세스 차단   |
| **스레드 생성 오버헤드**| 오버헤드가 큼                                | 오버헤드가 적음                              |

---

### 결론

- **프로세스 상태**는 프로세스가 실행되는 동안의 상태 변화를 나타내며, Ready, Running, Blocked 등으로 구분됩니다.
- **PCB**는 프로세스의 상태, 메모리 정보, 레지스터 값 등을 저장하는 데이터 구조로, 운영체제가 프로세스를 관리하는 데 중요한 역할을 합니다.
- **TCB**는 스레드의 상태와 정보를 관리하며, 스레드가 다중 작업을 수행할 때 중요한 역할을 합니다.
- **커널 스레드**는 운영체제가 직접 관리하는 스레드로, 병렬 처리가 가능하지만 문맥 교환 비용이 큽니다.
- **유저 스레드**는 사용자 레벨에서 관리되는 스레드로, 성능은 좋지만 운영체제와의 통합이 부족하여 한계가 있을 수 있습니다.

<br>
<br>
<br>
<hr>

## 스케줄러

**스케줄러(Scheduler)**는 운영체제에서 **CPU와 메모리 자원을 효율적으로 관리**하기 위해 **프로세스를 선택**하고 **실행 순서를 결정**하는 역할을 합니다. 운영체제에는 세 가지 주요 스케줄러가 있으며, 각각 **장기 스케줄러(Long-Term Scheduler)**, **중기 스케줄러(Medium-Term Scheduler)**, **단기 스케줄러(Short-Term Scheduler)**로 나뉩니다. 각 스케줄러는 다른 주기로 작동하며, 프로세스가 시스템 자원을 효율적으로 사용할 수 있도록 조정합니다.

### **1. 장기 스케줄러 (Long-Term Scheduler)**
- **역할**: 장기 스케줄러는 **디스크에서 메모리로 프로세스를 적재**하는 작업을 담당합니다. 즉, 시스템에 **얼마나 많은 프로세스가 동시에 실행**될지를 결정합니다. 
- **작동 방식**: 장기 스케줄러는 **새로운 프로세스가 생성될 때** 작동하며, 프로세스를 **디스크에서 메모리로 로드**하는 방식으로 **프로세스 풀(Process Pool)**을 관리합니다. 주로 **배치 시스템**이나 **대형 시스템**에서 많이 사용됩니다.
- **속도**: 장기 스케줄러는 상대적으로 **느리게 작동**하며, 자주 실행되지 않습니다. 
- **목표**: 시스템이 **적절한 수의 프로세스를 실행**할 수 있도록 조절하여, CPU와 메모리 자원의 균형을 유지하는 것이 목표입니다.
- **실행 대상**: **I/O 바운드** 프로세스(입출력 작업이 많아 CPU 사용이 적음)와 **CPU 바운드** 프로세스(연산 작업이 많아 CPU 사용이 많음)를 **균형 있게 선택**합니다.

---

### **2. 중기 스케줄러 (Medium-Term Scheduler)**
- **역할**: 중기 스케줄러는 **메모리에 올라와 있는 프로세스의 일시 중단(스와핑)**을 담당하며, **프로세스를 메모리에서 디스크로 이동**시킵니다. 이 과정은 주로 메모리 부족 상황에서 사용됩니다.
- **작동 방식**: **메모리 부족** 또는 **시스템 부하**가 높을 때, 실행 중인 프로세스 중 일부를 **스와핑 아웃**(메모리에서 디스크로 이동)하고, 이후 필요할 때 **스와핑 인**(디스크에서 메모리로 이동)하여 작업을 계속할 수 있도록 합니다.
- **속도**: 중기 스케줄러는 장기 스케줄러보다 자주 작동하지만, 여전히 상대적으로 느리게 작동합니다.
- **목표**: **시스템 자원을 최적화**하고, **프로세스가 중단 없이 재개**될 수 있도록 관리합니다. 주로 **멀티프로그래밍 환경**에서 프로세스를 메모리 내에서 효율적으로 관리하는 것이 목적입니다.

---

### **3. 단기 스케줄러 (Short-Term Scheduler)**
- **역할**: 단기 스케줄러는 **프로세스에 CPU를 할당**하는 역할을 담당합니다. 즉, 메모리에 있는 프로세스들 중 **어느 프로세스가 CPU를 사용할지**를 결정합니다.
- **작동 방식**: 단기 스케줄러는 매우 **빠르게 작동**하며, 프로세스가 **CPU 자원을 필요로 할 때마다** 즉각적으로 CPU를 할당합니다. 이 과정은 **수 밀리초** 단위로 매우 짧은 주기로 이루어집니다.
- **속도**: 단기 스케줄러는 **자주 실행**되며, 가장 빠른 스케줄러입니다. CPU가 할당되지 않은 상태를 최소화하는 것이 중요하기 때문에 신속하게 작동해야 합니다.
- **목표**: 단기 스케줄러의 주된 목표는 **프로세스의 실행 속도를 최적화**하는 것입니다. 가능한 한 많은 프로세스가 CPU를 효율적으로 사용하도록 하고, **응답 시간을 줄이는 것**이 목표입니다.
- **실행 대상**: **준비 상태(Ready)**에 있는 프로세스를 선택하여 CPU에 할당합니다.

---

### **각 스케줄러의 차이점 요약**

| **스케줄러 종류**     | **역할**                          | **주기**         | **속도**          | **목표**                                 |
|----------------------|-----------------------------------|-----------------|-------------------|-----------------------------------------|
| **장기 스케줄러**    | 프로세스를 디스크에서 메모리로 로드  | 적은 주기(느림)   | 느림              | 프로세스 풀 관리, CPU와 I/O 자원의 균형  |
| **중기 스케줄러**    | 프로세스를 메모리에서 디스크로 스와핑 | 중간 주기        | 중간              | 메모리 최적화, 프로세스 일시 중단 관리   |
| **단기 스케줄러**    | 프로세스에 CPU 할당               | 매우 빈번하게 실행 | 매우 빠름         | CPU 효율성 극대화, 응답 시간 최적화      |

---

### **결론**

- **장기 스케줄러**는 **메모리로 프로세스를 로드**하는 역할을 하며, 주로 시스템의 프로세스 풀 크기를 결정합니다.
- **중기 스케줄러**는 **스와핑**을 통해 메모리 사용을 최적화하고, 메모리 자원을 효율적으로 관리합니다.
- **단기 스케줄러**는 CPU 할당을 관리하여 **즉각적인 프로세스 실행**을 최적화하는 데 중요한 역할을 합니다.

각 스케줄러는 **다른 주기**와 **속도**로 작동하며, 운영체제는 이 스케줄러들을 사용하여 시스템 자원을 효율적으로 관리합니다.

<br>
<br>
<br>
<hr>


## cpu 스케줄러

**CPU 스케줄러**는 운영체제가 프로세스에게 CPU를 할당하는 **스케줄링 알고리즘**을 결정하는 중요한 역할을 합니다. CPU 스케줄링 알고리즘은 다양한 방식으로 프로세스를 스케줄링하여 CPU를 효율적으로 사용하고 시스템의 성능을 최적화합니다. 주요 CPU 스케줄링 알고리즘에는 **FCFS(First-Come, First-Served)**, **SJF(Shortest Job First)**, **SRTF(Shortest Remaining Time First)**, **Priority Scheduling(우선순위 스케줄링)**, **HRN(Highest Response Ratio Next)**, **Round Robin** 등이 있습니다.

### **1. FCFS (First-Come, First-Served) 스케줄링**

- **개념**: 가장 단순한 스케줄링 알고리즘으로, **먼저 도착한 프로세스가 먼저 실행**되는 방식입니다. 도착한 순서대로 CPU를 할당받기 때문에 큐(FIFO 구조)로 관리됩니다.
- **장점**: 구현이 매우 간단하며, 자원을 요청한 순서대로 처리되므로 **공정성**이 있습니다.
- **단점**: **Convoy Effect**라고 불리는 문제를 유발할 수 있습니다. 즉, 긴 프로세스가 먼저 도착하면, 뒤에 도착한 짧은 프로세스들이 오랫동안 대기하게 됩니다. **평균 대기 시간이 길어질** 수 있으며, 응답 시간이 느려집니다.
  
**예시**:  
프로세스 A(실행 시간 5초), B(2초), C(1초)가 순서대로 도착하면, A부터 실행되며 B와 C는 A가 끝날 때까지 기다려야 합니다.

---

### **2. SJF (Shortest Job First) 스케줄링**

- **개념**: **실행 시간이 가장 짧은 프로세스**를 먼저 실행하는 방식입니다. 각 프로세스의 실행 시간이 알고 있어야 적용할 수 있으며, **비선점형(Non-preemptive)** 알고리즘입니다.
- **장점**: **평균 대기 시간**이 최소화되며, 짧은 작업을 먼저 처리하기 때문에 **응답 시간이 빠릅니다**.
- **단점**: **실행 시간을 미리 알 수 없는 경우**에는 적용이 어렵고, 긴 작업이 계속해서 대기하게 되는 **Starvation(기아) 문제**가 발생할 수 있습니다.

**예시**:  
프로세스 A(5초), B(2초), C(1초)일 때, C부터 실행하고 B, A 순서로 실행하여 대기 시간을 최소화합니다.

---

### **3. SRTF (Shortest Remaining Time First) 스케줄링**

- **개념**: **SJF의 선점형(Preemptive) 버전**입니다. CPU가 할당된 프로세스가 있어도, 더 짧은 실행 시간을 가진 프로세스가 도착하면 **현재 실행 중인 프로세스를 중단**하고 더 짧은 프로세스를 먼저 실행합니다.
- **장점**: SJF보다 더 효율적이며, 응답 시간과 대기 시간을 더욱 최소화할 수 있습니다.
- **단점**: **문맥 교환 오버헤드**가 발생할 수 있으며, 역시 **Starvation 문제**가 발생할 가능성이 있습니다. 실행 시간 예측이 어려울 수 있습니다.

**예시**:  
프로세스 A(5초)가 실행 중인데, 프로세스 B(2초)가 도착하면 A를 중단하고 B가 먼저 실행됩니다. 이후 A는 남은 3초 동안 실행됩니다.

---

### **4. 우선순위 스케줄링 (Priority Scheduling)**

- **개념**: 각 프로세스에 **우선순위(우선권)**를 부여하고, **우선순위가 높은 프로세스**부터 CPU를 할당받습니다. 우선순위는 주로 **숫자로 표현**되며, 낮은 숫자가 더 높은 우선순위를 의미합니다. 비선점형과 선점형 모두 가능합니다.
- **장점**: **중요한 작업**을 먼저 처리할 수 있으며, **긴급한 작업**에 유리합니다.
- **단점**: **Starvation 문제**가 발생할 수 있습니다. 즉, 낮은 우선순위의 프로세스가 CPU를 거의 할당받지 못하고 계속 대기하게 될 수 있습니다. 이를 해결하기 위해 **Aging** 기법(Aging은 Starvation을 해결하는 방법 중 하나로 각각의 process마다 시간이 지나면 지날수록 우선순의를 높여주는 방법)을 사용하여, 오랫동안 대기한 프로세스의 우선순위를 점진적으로 높여주는 방식이 있습니다.

**예시**:  
프로세스 A(우선순위 3), B(우선순위 1), C(우선순위 2)일 때, 우선순위가 높은 B가 먼저 실행되고, 이후 C, A 순서로 실행됩니다.

---

### **5. HRN (Highest Response Ratio Next) 스케줄링**

- **개념**: **우선순위 스케줄링**과 **SJF**의 장점을 결합한 방식입니다. 각 프로세스의 **응답 비율**을 계산하여 가장 높은 응답 비율을 가진 프로세스부터 실행합니다. 응답 비율은 다음과 같이 계산됩니다:
  
  \[
  \text{응답 비율} = \frac{\text{대기 시간} + \text{서비스 시간}}{\text{서비스 시간}}
  \]
  
  즉, 오래 기다린 프로세스는 대기 시간 때문에 응답 비율이 높아져 우선적으로 처리됩니다.
  
- **장점**: **Starvation 문제**를 해결하면서도, SJF처럼 짧은 작업을 우선적으로 처리할 수 있습니다.
- **단점**: 상대적으로 복잡하며, 시스템에 따라 추가 계산이 필요할 수 있습니다.

**예시**:  
프로세스 A(대기 시간 10, 실행 시간 2), B(대기 시간 1, 실행 시간 1), C(대기 시간 5, 실행 시간 4)일 때, 응답 비율을 계산하면 A가 먼저 실행됩니다.  
  A의 응답 비율: \((10 + 2)/2 = 6\)  
  B의 응답 비율: \((1 + 1)/1 = 2\)  
  C의 응답 비율: \((5 + 4)/4 = 2.25\)

---

### **6. 라운드 로빈 (Round Robin) 스케줄링**

- **개념**: **정해진 시간(Time Quantum)** 동안 각 프로세스에 CPU를 할당하며, 모든 프로세스를 **순환**하면서 처리하는 방식입니다. 시간 할당량이 지나면 **문맥 교환**이 일어나며, 다음 프로세스에 CPU가 할당됩니다.
- **장점**: **응답 시간이 일정**하며, **공정성**이 높습니다. 모든 프로세스가 **동등하게 CPU를 할당받을 기회**를 가집니다.
- **단점**: 시간 할당량이 너무 크면 **FCFS와 유사**해지고, 너무 작으면 **문맥 교환 오버헤드**가 커집니다. 따라서 적절한 시간 할당량을 설정하는 것이 중요합니다.

**예시**:  
프로세스 A(5초), B(2초), C(1초)가 있고, 시간 할당량이 2초일 경우, 먼저 A가 2초 동안 실행되고, B가 2초 실행된 후, C가 1초 동안 실행됩니다. 이후 남은 A의 3초가 다시 할당됩니다.

---

### **CPU 스케줄링 알고리즘 요약**

| **스케줄링 알고리즘**  | **설명**                                                            | **장점**                                           | **단점**                                          |
|------------------------|---------------------------------------------------------------------|----------------------------------------------------|---------------------------------------------------|
| **FCFS**               | 먼저 도착한 프로세스가 먼저 실행됨                                   | 공정하고 구현이 간단함                             | 긴 프로세스가 먼저 오면 평균 대기 시간이 길어짐    |
| **SJF**                | 실행 시간이 짧은 프로세스가 먼저 실행됨                              | 평균 대기 시간 최소화                              | 실행 시간을 예측하기 어려우며, Starvation 문제 발생 |
| **SRTF**               | 남은 실행 시간이 가장 짧은 프로세스가 먼저 실행됨                    | 응답 시간과 대기 시간이 최소화됨                   | 문맥 교환 오버헤드, Starvation 문제 발생           |
| **Priority Scheduling**| 우선순위가 높은 프로세스가 먼저 실행됨                               | 중요한 작업을 먼저 처리 가능                       | Starvation 문제 발생 가능, Aging으로 해결 가능     |
| **HRN**                | 응답 비율이 높은 프로세스를 먼저 실행함                               | Starvation 문제 해결, 짧은 작업 우선                | 계산이 복잡할 수 있음                             |
| **Round Robin**        | 정해진 시간 할당량 동안 각 프로세스를 순환하면서 실행                 | 응답 시간이 일정하고, 공정성 보장                   | 시간 할당량 설정이 중요, 문맥 교환 오버헤드 발생   |

---

<br>
<br>
<br>
<hr>


## 프로세스 동기화


**프로세스 동기화**는 다중 프로세스 또는 스레드가 공유 자원에 동시에 접근하는 상황에서 **정상적인 결과**를 보장하기 위한 기술입니다. 여러 프로세스나 스레드가 **동시에 실행**되면서, 공유 자원에 **동시 접근**할 때 **경쟁 상태(Race Condition)**가 발생할 수 있고, 이러한 문제를 해결하기 위해 **임계 영역(Critical Section)**을 설정하여 상호 배제를 보장해야 합니다. 이를 위해 다양한 동기화 기법, 예를 들어 **Mutex(뮤텍스)**, **Semaphore(세마포어)**, **Monitor(모니터)** 등이 사용됩니다. 이러한 동기화 과정에서 **데드락(Deadlock)** 문제가 발생할 수 있으며, 이를 방지하기 위한 여러 기법도 존재합니다.

### **1. 경쟁 상태 (Race Condition)**

**경쟁 상태**는 **여러 프로세스나 스레드가 동시에 공유 자원에 접근**하여 **결과가 예측할 수 없거나 비정상적인 상태**가 되는 것을 말합니다. 즉, **작업의 완료 순서에 따라 결과가 달라지는 상황**을 의미합니다.

- **경쟁 상태 발생 상황**: 예를 들어, 두 개의 스레드가 동시에 동일한 변수에 접근하여 값을 증가시키는 작업을 수행할 때, 스레드 간 순서가 잘못될 경우 값이 올바르게 증가하지 않을 수 있습니다.
  
  예시:  
  ```
  Thread 1: x = x + 1
  Thread 2: x = x + 1
  ```
  두 스레드가 동시에 변수 `x`에 접근하면, `x` 값이 의도한 대로 2만큼 증가하지 않을 수 있습니다. 이 상황이 **경쟁 상태**입니다.

---

### **2. 임계 영역 (Critical Section)**

**임계 영역**은 **공유 자원에 접근하는 코드 영역**으로, 동시에 여러 프로세스나 스레드가 진입하면 문제가 발생할 수 있는 영역입니다. 따라서 **동시에 하나의 프로세스만** 임계 영역에 들어갈 수 있도록 해야 하며, 이를 위해 **상호 배제(Mutual Exclusion)**를 보장해야 합니다.

- **해결책**: 임계 영역 문제를 해결하기 위해 여러 동기화 기법이 존재하며, 이들 기법은 임계 영역에 진입하는 프로세스나 스레드를 제어합니다. 대표적인 동기화 기법으로는 **Lock**, **Semaphore**, **Monitor**가 있습니다.

---

### **3. Mutex Lock과 Semaphore**

#### **Mutex (뮤텍스)**
- **개념**: **뮤텍스(Mutex)**는 **상호 배제**를 구현하는 가장 기본적인 메커니즘으로, **하나의 프로세스 또는 스레드만** 임계 영역에 접근할 수 있도록 하는 **잠금(Lock)** 장치입니다. 
- **동작**: 프로세스가 임계 영역에 진입할 때 뮤텍스를 **잠금** 상태로 설정하고, 다른 프로세스는 이 잠금이 해제될 때까지 대기합니다. 작업이 끝나면 뮤텍스를 **해제**하여 다른 프로세스가 임계 영역에 진입할 수 있게 합니다.
- **특징**: 뮤텍스는 **이진 상태**를 가지며, 임계 영역에 진입하는 **오직 하나의 프로세스만을 허용**합니다.

#### **Semaphore (세마포어)**
- **개념**: **세마포어(Semaphore)**는 **카운터**를 기반으로 하는 동기화 기법으로, **여러 개의 프로세스가 자원을 공유**할 수 있도록 허용합니다. 세마포어는 **정수 값**을 사용하여 자원 접근을 제어합니다.
- **동작**: 세마포어는 두 가지 연산인 **P 연산(wait)**과 **V 연산(signal)**을 통해 동작합니다. 세마포어의 값이 양수일 때는 접근이 가능하지만, 값이 0이거나 음수일 때는 자원이 모두 사용 중이므로 대기 상태가 됩니다.
- **특징**: 세마포어는 **N개의 프로세스가 자원에 동시에 접근**할 수 있게 하며, 이를 통해 **다중 자원**을 관리할 수 있습니다.

#### **Mutex와 Semaphore의 차이점**
| **특징**               | **Mutex**                                       | **Semaphore**                               |
|------------------------|------------------------------------------------|---------------------------------------------|
| **동작 방식**           | 한 번에 **하나의 프로세스**만 접근 가능         | **여러 프로세스**가 동시에 접근 가능 (카운팅 가능)|
| **값**                 | 이진 상태 (0 또는 1)                           | 정수 값 (0 이상)                            |
| **사용 목적**           | 하나의 자원에 대한 **상호 배제**                | 여러 자원에 대한 접근 관리                  |
| **잠금 해제**           | **잠금한 프로세스**만 잠금 해제 가능             | 누구나 해제할 수 있음                        |

---

### **4. 데드락 (Deadlock)**

**데드락(교착 상태)**는 **여러 프로세스가 서로가 점유한 자원을 기다리며** **무한정 대기 상태**에 빠지는 문제를 말합니다. 즉, 서로의 자원이 해제되기를 기다리며 **아무 작업도 진행하지 못하는 상태**가 됩니다.

- **데드락 발생 조건**:
  1. **상호 배제**: 자원이 한 번에 하나의 프로세스에만 할당됩니다.
  2. **점유 대기**: 자원을 점유한 프로세스가 다른 자원을 기다리면서 자원을 점유하고 있습니다.
  3. **비선점**: 자원을 강제로 빼앗을 수 없습니다.
  4. **환형 대기**: 프로세스들이 자원을 서로 기다리며 **원형 대기 상태**를 형성합니다.

---

### **5. 데드락 예방, 회피, 무시**

#### **데드락 예방(Prevention)**
데드락을 예방하기 위해 **데드락 발생 조건 중 하나 이상을 방지**합니다.
- **상호 배제** 조건을 피할 수 없는 경우가 많기 때문에, 주로 **점유 대기**, **비선점**, **환형 대기** 조건을 완화하여 예방합니다.
- **점유 대기 방지**: 프로세스가 자원을 할당받기 전에 필요한 모든 자원을 미리 할당받게 하여 점유 대기를 방지합니다.
- **비선점 방지**: 자원을 점유한 프로세스가 다른 자원을 요청할 경우, 현재 자원을 반납하고 다시 요청하게 합니다.
- **환형 대기 방지**: 자원에 번호를 부여하고, 프로세스가 자원을 할당받을 때 **순서대로 요청**하도록 하여 환형 대기를 방지합니다.

#### **데드락 회피(Avoidance)**
- **데드락 회피**는 자원의 상태를 지속적으로 추적하고, **안전 상태**를 유지하도록 자원을 할당하는 방식입니다. 대표적인 알고리즘으로 **은행가 알고리즘(Banker's Algorithm)**이 있습니다.
- 은행가 알고리즘은 **자원의 가용 상태와 프로세스의 최대 자원 요청**을 기반으로, **데드락이 발생하지 않는 안전한 자원 할당**을 합니다. 자원을 할당할 때 데드락이 발생할 가능성이 있으면 자원을 할당하지 않습니다.

#### **데드락 무시(Ignoring Deadlock)**
- 현실적인 상황에서 데드락은 **드물게 발생**하므로, **운영체제는 데드락 문제를 무시**하고 시스템을 계속 운영할 수 있습니다.
- 주로 **Unix, Linux, Windows** 같은 상용 운영체제는 데드락을 탐지하거나 해결하지 않고 **무시**합니다. 데드락이 발생하면 시스템 재부팅으로 해결하는 경우가 많습니다.

---

### **결론**

- **경쟁 상태(Race Condition)**는 여러 프로세스가 동시에 자원에 접근할 때 발생하는 문제로, **임계 영역(Critical Section)**에서 발생하며 동기화를 통해 해결해야 합니다.
- **Mutex**는 단일 자원에 대한 상호 배제를 보장하고, **Semaphore**는 다중 자원의 접근을 제어합니다.
- **데드락**은 프로세스들이 서로 자원을 기다리며 무한 대기 상태에 빠지는 문제로, 이를 예방, 회피, 또는 무시하는 방식으로 해결할 수 있습니다.


<br>
<br>
<br>
<hr>
